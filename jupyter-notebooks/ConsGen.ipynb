{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e05d0d-01eb-4ad3-8e34-186f85a6fcfd",
   "metadata": {},
   "source": [
    "## Conservation Genomics Practical\n",
    "\n",
    "------------------------ \n",
    "**Background**:\n",
    "This notebook originates from a practical I completed for Cornell's BIOCB 2010: Intro to Computational Biology. This notebook exists for the historical purpose of what the program used to be.\n",
    "\n",
    "The primary data for modern conservation genomics efforts often includes whole-genome\n",
    "sequences of multiple individuals of a threatened species. From this data, we infer the levels\n",
    "and patterns of genetic diversity, and apply population genetics models to infer past\n",
    "demography. We can also infer levels of inbreeding and patterns of migration from sequence\n",
    "data. If we have access to information about the deleterious consequences of variants, or we\n",
    "apply computation inference of those deleterious effects, we can further infer\n",
    "<br>\n",
    "<br>\n",
    "I have four sets of sequence data, all drawn from one chromosome, from four different populations with distinct population histories. The data consist of only the segregating sites, with “0” being the ancestral allele, and “1” being the derived allele. Each row represents a haplotype drawn from the population, and each dataset consists of 50 such\n",
    "haplotypes.\n",
    "I will randomly select one of the blocks from each data file, and, for each data set, I will:\n",
    "1. Read in the data into a matrix\n",
    "2. Calculate the nucleotide diversity, pi (the data are the segregating sites **only**, out of a span of 10 kb).\n",
    "3. Determine the number of segregating sites, S.\n",
    "4. Calculate Watterson’s theta.\n",
    "5. Calculate Tajima’s D\n",
    "\n",
    "**Equations:** <br>\n",
    "Watterson's estimator ($\\theta$) <br>\n",
    "&nbsp; $\\theta=\\frac{S}{\\sum \\limits_{i=1}^{n-1}1/i}$ &nbsp; ; &nbsp; where $S$=segregating sites, $n$=the number of loci (columns). <br>\n",
    "<br>\n",
    "Average nucleotide diversity ($\\pi$) <br>\n",
    "&nbsp; $ \\pi=\\frac{1}{L} \\sum\\limits_{k=1}^{L}h_k$ &nbsp; ; &nbsp; where $h_{k}=\\frac{2p(n-p)}{n(n-1)}$ , $L$=number of loci (i.e. nucelotide positions / columns), $n$=sample size (number of haplotypes/rows) , and $p$=number of derived alleles (1's) at loci $k$. <br>\n",
    "<br>\n",
    "Tajima's $D$ <br>\n",
    "$D=\\frac{\\pi-\\theta}{SD(\\pi-\\theta)}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7579086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import random\n",
    "#from scipy.stats import tajima_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4adac9e2-eade-45b9-9e0a-eb01b4642e47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9   ...  62  63  64  65  66  67  68  \\\n",
      "0    0   0   1   0   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "1    1   0   1   0   0   0   0   1   0   0  ...   0   1   0   0   1   0   1   \n",
      "2    0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "3    0   0   1   0   0   1   0   1   1   0  ...   0   0   0   0   1   0   1   \n",
      "4    0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "5    0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "6    0   0   1   0   1   0   0   1   0   1  ...   0   0   1   0   1   0   1   \n",
      "7    0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "8    0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "9    0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "10   0   1   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   0   0   \n",
      "11   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "12   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   0   1   0   1   \n",
      "13   0   0   1   0   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "14   0   0   1   0   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "15   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "16   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "17   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "18   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   1   0   \n",
      "19   0   0   1   0   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "20   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "21   0   0   1   0   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "22   0   1   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   0   0   \n",
      "23   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   1   1   0   1   \n",
      "24   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "25   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "26   1   0   1   0   0   0   0   1   0   0  ...   0   1   0   0   1   0   1   \n",
      "27   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   1   1   0   1   \n",
      "28   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "29   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "30   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "31   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   1   1   0   1   \n",
      "32   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   1   1   0   1   \n",
      "33   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "34   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "35   1   0   1   0   0   0   0   1   0   0  ...   0   1   0   0   1   0   1   \n",
      "36   0   0   1   0   0   1   1   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "37   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "38   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "39   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "40   0   1   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   0   0   \n",
      "41   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "42   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "43   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "44   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   0   1   0   1   \n",
      "45   0   0   1   0   0   1   0   1   0   0  ...   0   0   0   0   1   0   1   \n",
      "46   0   0   1   1   0   0   0   1   0   0  ...   0   0   1   0   1   0   1   \n",
      "47   0   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "48   0   0   1   0   1   0   0   1   0   1  ...   0   0   1   0   1   0   1   \n",
      "49   0   0   1   0   0   1   0   1   1   0  ...   0   0   0   0   1   0   1   \n",
      "\n",
      "    69  70  71  \n",
      "0    1   0   0  \n",
      "1    0   0   1  \n",
      "2    0   0   0  \n",
      "3    0   0   0  \n",
      "4    0   1   0  \n",
      "5    0   1   0  \n",
      "6    0   0   0  \n",
      "7    0   1   0  \n",
      "8    0   1   0  \n",
      "9    0   0   0  \n",
      "10   0   1   0  \n",
      "11   0   1   0  \n",
      "12   0   0   0  \n",
      "13   0   0   0  \n",
      "14   1   0   0  \n",
      "15   0   1   0  \n",
      "16   0   1   0  \n",
      "17   0   1   0  \n",
      "18   0   1   0  \n",
      "19   0   0   0  \n",
      "20   0   1   0  \n",
      "21   0   0   0  \n",
      "22   0   1   0  \n",
      "23   0   0   0  \n",
      "24   0   1   0  \n",
      "25   0   1   0  \n",
      "26   0   0   1  \n",
      "27   0   0   0  \n",
      "28   0   0   0  \n",
      "29   0   1   0  \n",
      "30   0   1   0  \n",
      "31   0   0   0  \n",
      "32   0   0   0  \n",
      "33   0   1   0  \n",
      "34   0   1   0  \n",
      "35   0   0   1  \n",
      "36   0   0   0  \n",
      "37   0   0   0  \n",
      "38   0   1   0  \n",
      "39   0   1   0  \n",
      "40   0   1   0  \n",
      "41   0   0   0  \n",
      "42   0   0   0  \n",
      "43   0   0   0  \n",
      "44   0   0   0  \n",
      "45   0   0   0  \n",
      "46   0   0   0  \n",
      "47   0   1   0  \n",
      "48   0   0   0  \n",
      "49   0   0   0  \n",
      "\n",
      "[50 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Input matrices \n",
    "def load_haplotype_data(file_path):\n",
    "    with open(file_path, 'r') as file:    # 'r' = read mode\n",
    "        blocks = file.read().split('\\n\\n')   #split file in to blocks from newlines\n",
    "        block = random.choice(blocks)\n",
    "        processed_lines = []\n",
    "        # from each file, select one block at random,\n",
    "        for line in block.strip().split('\\n'):\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line.replace(\",\", \"\").isdigit():\n",
    "                processed_lines.append(stripped_line.split(','))\n",
    "        return pd.DataFrame(processed_lines).astype(int) \n",
    "    # each block consists of haplotypes from 50 individuals (rows)\n",
    "\n",
    "# Initialize a list to store each haplotype matrix\n",
    "haplotype_blocks = []\n",
    "\n",
    "# Need to do the following for all 4 blocks selected from the 4 files.\n",
    "#hapmx = pd.read_csv('ConGensData1block1.txt', sep = ',', header=None)\n",
    "hapmx1 = load_haplotype_data('Data/ConsGenData1.txt')\n",
    "hapmx2 = load_haplotype_data('Data/ConsGenData2.txt')\n",
    "hapmx3 = load_haplotype_data('Data/ConsGenData3.txt')\n",
    "hapmx4 = load_haplotype_data('Data/ConsGenData4.txt')\n",
    "\n",
    "haplotype_blocks.extend([hapmx1, hapmx2, hapmx3, hapmx4])\n",
    "\n",
    "print(haplotype_blocks[0]) #display first matrix for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58051c04-27b4-4490-be14-0a4d7a89692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleotide diversity (pi) for block 1: 0.2638095238095237\n",
      "Nucleotide diversity (pi) for block 2: 0.15102990033222569\n",
      "Nucleotide diversity (pi) for block 3: 0.30892128279883363\n",
      "Nucleotide diversity (pi) for block 4: 0.27052947052947035\n"
     ]
    }
   ],
   "source": [
    "# Calculate nucelotide diversity (pi)\n",
    "def calc_pi(haplotypes):\n",
    "    # variables\n",
    "    n = haplotypes.shape[0]  # number of haplotypes (rows)\n",
    "    L = haplotypes.shape[1]  # number of loci (columns)\n",
    "    # calculations\n",
    "    if L == 0:\n",
    "        return 0\n",
    "    pi_total = 0\n",
    "    for k in range(L):\n",
    "        p = np.sum(haplotypes.iloc[:, k] == 1)  # number of derived alleles (1's) at loci k\n",
    "        h_k = 2 * p * (n - p) / (n * (n - 1))\n",
    "        pi_total += h_k\n",
    "    \n",
    "    #formula\n",
    "    pi = pi_total / L  # avg nucleotide diversity\n",
    "    return pi\n",
    "\n",
    "for i, haplotype_block in enumerate(haplotype_blocks):\n",
    "    result_pi = calc_pi(haplotype_block)\n",
    "    #edited to look at each block\n",
    "    print(f\"Nucleotide diversity (pi) for block {i+1}: {result_pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac6b58d4-7b8c-45ff-8be4-cefded451f19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segregating sites (S) for block 1: 72 out of 91 sites.\n",
      "Number of segregating sites (S) for block 2: 86 out of 91 sites.\n",
      "Number of segregating sites (S) for block 3: 42 out of 91 sites.\n",
      "Number of segregating sites (S) for block 4: 90 out of 91 sites.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of segregating sites (S)\n",
    "def count_segregating_sites(haplotypes):\n",
    "    n = len(haplotypes.axes[1])\n",
    "    S = 0\n",
    "    for i in range(0,n):\n",
    "        if len(haplotypes[i].unique()) == 1: \n",
    "            S = S\n",
    "        else:\n",
    "            S = S + 1\n",
    "    return S\n",
    "\n",
    "for i, hapmx in enumerate(haplotype_blocks):\n",
    "    result_S = count_segregating_sites(hapmx)\n",
    "    print(f\"Number of segregating sites (S) for block {i+1}: {result_S} out of {haplotype_block.shape[1]} sites.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4835e04-d93c-4260-bb67-ca0e3d596c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wattersons theta for block 1: 16.074279824566677\n",
      "Wattersons theta for block 2: 19.199834234899082\n",
      "Wattersons theta for block 3: 9.376663230997227\n",
      "Wattersons theta for block 4: 20.582127074853084\n"
     ]
    }
   ],
   "source": [
    "# Calculate Wattersons theta\n",
    "def calc_watterson(haplotypes):\n",
    "    n = haplotypes.shape[0]  # number of haplotypes (rows)\n",
    "    L = haplotypes.shape[1]  # number of loci (columns)\n",
    "    # S = segregating sites\n",
    "    S = count_segregating_sites(haplotypes)\n",
    "    # a = sum(1/i)\n",
    "    a = 0\n",
    "    for i in range(1,n):\n",
    "        a += (1/i)\n",
    "    # pi = S / a ...\n",
    "    if a != 0:\n",
    "        theta = S / a\n",
    "    else:\n",
    "        theta = 0\n",
    "    return theta\n",
    "\n",
    "for i, hapmx in enumerate(haplotype_blocks):\n",
    "    result_watt = calc_watterson(hapmx)\n",
    "    print(f\"Wattersons theta for block {i+1}: {result_watt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20781ebc-e7ed-48bf-b092-63106fce8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tajima's D for block 1: -3.455914083326963\n",
      "Tajima's D for block 2: -3.509513121942796\n",
      "Tajima's D for block 3: -3.3022089575884257\n",
      "Tajima's D for block 4: -3.5444011615850655\n"
     ]
    }
   ],
   "source": [
    "# Calculate Tajima's D\n",
    "def tajimas_d(haplotypes):\n",
    "    # variables\n",
    "    n = haplotypes.shape[0]  # number of haplotypes (rows)\n",
    "    pi = calc_pi(haplotypes)\n",
    "    theta = calc_watterson(haplotypes)\n",
    "    S = count_segregating_sites(haplotypes)\n",
    "\n",
    "    # formulas and calculations\n",
    "    a1 = np.sum([1/i for i in range(1, n)])  # Sum of 1/i from 1 to n-1\n",
    "    a2 = np.sum([1/(i**2) for i in range(1, n)])  # Sum of 1/i^2 from 1 to n-1\n",
    "\n",
    "    b1 = (n + 1) / (3 * (n - 1))\n",
    "    b2 = 2 * (n**2 + n + 3) / (9 * n * (n - 1))\n",
    "    c1 = b1 - (1 / a1)\n",
    "    c2 = b2 - ((n + 2) / (a1 * n)) + (a2 / (a1**2))\n",
    "    e1 = c1 / a1\n",
    "    e2 = c2 / (a1**2 + a2)\n",
    "\n",
    "        # Variance of pi - theta\n",
    "    variance = (e1 * S) + (e2 * S * (S - 1))\n",
    "    \n",
    "    sd = np.sqrt(variance)\n",
    "\n",
    "    # Tajima's D calculation\n",
    "    if sd != 0:\n",
    "        tajimas_d = (pi - theta) / sd\n",
    "    else:\n",
    "        tajimas_d = 0\n",
    "    return tajimas_d\n",
    "\n",
    "# made it a for loop to show all the blocks\n",
    "for i, hapmx in enumerate(haplotype_blocks):\n",
    "    result_tajimas_d = tajimas_d(hapmx)\n",
    "    print(f\"Tajima's D for block {i+1}: {result_tajimas_d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
